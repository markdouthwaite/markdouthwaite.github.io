<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-12-29T22:24:57+00:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Mark Douthwaite</title><subtitle>Blogs, thoughts and noise.</subtitle><author><name>Mark Douthwaite</name></author><entry><title type="html">Reservoir Computing: Turning almost any object into a computer</title><link href="http://localhost:4000/ReservoirComputers/" rel="alternate" type="text/html" title="Reservoir Computing: Turning almost any object into a computer" /><published>2018-12-01T00:00:00+00:00</published><updated>2018-12-01T00:00:00+00:00</updated><id>http://localhost:4000/ReservoirComputers</id><content type="html" xml:base="http://localhost:4000/ReservoirComputers/">&lt;p&gt;&lt;img src=&quot;https://www.calacademy.org/sites/default/files/assets/images/Education_Images/TYE_Images/earthswater_waterdrop_usdanrcs1200x900.jpg&quot; alt=&quot;droplet&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The latest chip in the iPhone 7 has 3.3 billion transistors packed into a piece of silicon around the size of a small coin. But the trend for smaller, increasingly powerful computers could be coming to an end. Silicon-based chips are rapidly reaching a point at which the laws of physics prevent them being any smaller. There are also some important limitations to what silicon-based devices can do that mean there is a strong argument for looking at other ways to power computers.&lt;/p&gt;

&lt;p&gt;Perhaps the most well-known alternative researchers are looking at is quantum computers, which manipulate the properties of the chips in a different way to traditional digital machines. But there is also the possibilty of using alternative materials – potentially any material or physical system – as computers to perform calculations, without the need to manipulate electrons like silicon chips do. And it turns out these could be even better for developing artificial intelligence than existing computers.&lt;/p&gt;

&lt;p&gt;The idea is commonly known as “reservoir computing” and came from attempts to develop computer networks modelled on the brain. It involves the idea that we can tap into the behaviour of physical systems – anything from a bucket of water to blobs of plastic laced with carbon nanotubes – in order to harness their natural computing power.&lt;/p&gt;

&lt;h2 id=&quot;input-and-output&quot;&gt;Input and output&lt;/h2&gt;

&lt;p&gt;Reservoir computers exploit the physical properties of a material in its natural state to do part of a computation. This contrasts with the current digital computing model of changing a material’s properties to perform computations. For example, to create modern microchips we alter the crystal structure of silicon. A reservoir computer could, in principle, be made from a piece of silicon (or any number of other materials) without these design modifications.&lt;/p&gt;

&lt;p&gt;The basic idea is to stimulate a material in some way and learn to measure how this affects it. If you can work out how you get from the input stimulation to the output change, you will effectively have a calculation that you can then use as part of a range of computations. Unlike with traditional computer chips that depend on the position of electrons, the specific arrangement of the particles in the material isn’t important. Instead we just need to observe certain overall properties that let us measure the output change in the material.&lt;/p&gt;

&lt;p&gt;For example, one team of researchers has built a simple reservoir computer out of a bucket of water. They demonstrated that, after stimulating the water with mechanical probes, they could train a camera watching the water’s surface to read the distinctive ripple patterns that formed. They then worked out the calculation that linked the probe movements with the ripple pattern, and then used it to perform some simple logical operations. Fundamentally, the water itself was transforming the input from the probes into a useful output –- and that is the great insight.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://images.theconversation.com/files/141201/original/image-20161011-3894-1kxax9j.jpg?ixlib=rb-1.1.0&amp;amp;q=30&amp;amp;auto=format&amp;amp;w=600&amp;amp;h=428&amp;amp;fit=crop&amp;amp;dpr=2&quot; alt=&quot;Generic Brain Image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;general-purpose-brain-cells&quot;&gt;General purpose brain cells&lt;/h2&gt;

&lt;p&gt;It turns out that this idea of reservoir computing aligns with recent neuroscience research that discovered parts of the brain appear to be “general-purpose”. These areas are predominantly made up of collections of neurons that are only loosely ordered yet can still support cognitive function in more specialised parts of the brain, helping to make it more efficient. As with the computer, if this reservoir of neurons is stimulated with a specific signal it will respond in a very characteristic way, and this response can help perform computations.&lt;/p&gt;

&lt;p&gt;For example, recent work suggests that when we hear or see something, one general part of the brain is stimulated by sound or light. The response of the neurons in that area of the brain is then read by another more specialised area of the brain.&lt;/p&gt;

&lt;p&gt;Research indicates that reservoir computers could be extremely robust and computationally powerful and, in theory, could effectively carry out an infinite number of functions. In fact, simulated reservoirs have already become very popular in some aspects of artificial intelligence thanks to precisely these properties. For example, systems using reservoir methods for making stock-market predictions have indicated that they outperform many conventional artificial intelligence technologies. In part, this is because it turns out to be much easier to train AI that harnesses the power of a reservoir than one that does not.&lt;/p&gt;

&lt;p&gt;Ultimately, this is still a relatively new technology and a good deal of research remains to be done into its capabilities and implications. But it is already clear that there are a huge number of potential applications of this type of technology both in AI and more broadly. This could include anything from analysing and processing real-time data to image/pattern recognition and controlling robots.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Originally posted on The Conversation, &lt;a href=&quot;https://theconversation.com/theres-a-way-to-turn-almost-any-object-into-a-computer-and-it-could-cause-shockwaves-in-ai-62235&quot;&gt;here&lt;/a&gt; in collaboration with Matt Dale.&lt;/em&gt;&lt;/p&gt;</content><author><name>Mark Douthwaite</name></author><category term="artificial intelligence" /><category term="engineering" /><summary type="html">Reservoir computers exploit the physical properties of a material in its natural state to do part of a computation. This contrasts with the current digital computing model of changing a material’s properties to perform computations. For example, to create modern microchips we alter the crystal structure of silicon. A reservoir computer could, in principle, be made from a piece of silicon (or any number of other materials) without these design modifications.</summary></entry><entry><title type="html">Python Utilities for Data Scientists - Part 1: tqdm</title><link href="http://localhost:4000/NonDataSciencePackagesForDataSciencept1tqdm/" rel="alternate" type="text/html" title="Python Utilities for Data Scientists - Part 1: tqdm" /><published>2018-12-01T00:00:00+00:00</published><updated>2018-12-01T00:00:00+00:00</updated><id>http://localhost:4000/NonDataSciencePackagesForDataSciencept1tqdm</id><content type="html" xml:base="http://localhost:4000/NonDataSciencePackagesForDataSciencept1tqdm/">&lt;p&gt;This series of posts is going to give an overview of some interesting, useful and/or time-saving general-purpose packages that can make the lives of Data Scientists a little easier. I thought I’d put this together after finding a few-to-many DS repositories, scripts and notebooks that made life far too difficult for themselves.&lt;/p&gt;

&lt;h2 id=&quot;tqdm&quot;&gt;TQDM&lt;/h2&gt;

&lt;p&gt;To kick things off, let’s look at &lt;code class=&quot;highlighter-rouge&quot;&gt;tqdm&lt;/code&gt;, a fantastic, easy-to-use, extensible progress bar package. It makes adding fast, informative progress bars to Python processes extremely easy. If you’re a Data Scientist or Machine Learning (ML) Engineer with any degree of experience, you’ll no doubt have used or developed algorithms or data transformations that can take many hours to complete.&lt;/p&gt;

&lt;p&gt;Invariably, many Data Scientists opt to simply print status messages to console, or in some slightly more sophisticated cases use the (excellent and recommended) built-in &lt;code class=&quot;highlighter-rouge&quot;&gt;logging&lt;/code&gt; module. In a lot of cases this is fine. However, if you’re running a task with many hundreds of steps, or over a data structure with many millions of elements, these approaches are sometimes a little unclear and gratuitous, and frankly kind of ugly.&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;http://mark.douthwaite.io/wp-content/uploads/2018/11/Screenshot-2018-11-26-at-22.20.37-1024x104.png&quot; sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot; srcset=&quot;http://mark.douthwaite.io/wp-content/uploads/2018/11/Screenshot-2018-11-26-at-22.20.37-1024x104.png 1024w, http://mark.douthwaite.io/wp-content/uploads/2018/11/Screenshot-2018-11-26-at-22.20.37-300x31.png 300w, http://mark.douthwaite.io/wp-content/uploads/2018/11/Screenshot-2018-11-26-at-22.20.37-768x78.png 768w, http://mark.douthwaite.io/wp-content/uploads/2018/11/Screenshot-2018-11-26-at-22.20.37.png 1080w&quot; alt=&quot;&quot; width=&quot;1024&quot; height=&quot;104&quot; /&gt;&lt;figcaption&gt;Example output from &lt;code class=&quot;prettyprint&quot;&gt;tqdm&lt;/code&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;That’s where &lt;code class=&quot;highlighter-rouge&quot;&gt;tqdm&lt;/code&gt; can come in. It has a nice clean API that lets us quickly add progress bars to our code. Plus it has a lightweight ‘time-remaining’ estimation algorithm built in to the progress bar too. When I first came across &lt;code class=&quot;highlighter-rouge&quot;&gt;tqdm&lt;/code&gt; (while exploring the &lt;code class=&quot;highlighter-rouge&quot;&gt;implicit&lt;/code&gt; library), my mind immediately went to how I could use it to make my own ML algorithm outputs a lot tidier. Take a look at the example below:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tqdm&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Training Epoch&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;progress&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;progress&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# increments the progress bar
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this simple example, we set up a &lt;code class=&quot;highlighter-rouge&quot;&gt;tqdm&lt;/code&gt; progress bar that expects a process of 100 steps. We then run our mock training loop, each time updating the progress bar when the step is completed. We can also update the progress bar by arbitrary amounts if we break out of the loop too. That’s two lines of code (plus the import statement) to get a rich progress bar in your code.&lt;/p&gt;

&lt;h2 id=&quot;pandas-integration&quot;&gt;Pandas Integration&lt;/h2&gt;

&lt;p&gt;Beyond cool little additions to your program’s outputs,&lt;code class=&quot;highlighter-rouge&quot;&gt;tqdm&lt;/code&gt;&amp;lt;/code&amp;gt;`also integrates nicely with other widely used packages. Probably the most interesting integration for Data Scientists is with Pandas, the ubiquitous Python data analysis library. Take a look at the example below:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;weather.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Applying Transformation&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;progress_apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This would give us:&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;http://mark.douthwaite.io/wp-content/uploads/2018/11/Screenshot-2018-12-01-at-12.41.27.png&quot; sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot; alt=&quot;&quot; width=&quot;1024&quot; height=&quot;104&quot; /&gt;&lt;figcaption&gt;Example output from `tqdm`&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Technically, the &lt;code class=&quot;highlighter-rouge&quot;&gt;tqdm.pandas&lt;/code&gt; method monkey patches the &lt;code class=&quot;highlighter-rouge&quot;&gt;progress_apply&lt;/code&gt; method onto Pandas data structures, giving them a modified version of the commonly used &lt;code class=&quot;highlighter-rouge&quot;&gt;apply&lt;/code&gt; method. Practically, when we call the &lt;code class=&quot;highlighter-rouge&quot;&gt;progress_apply&lt;/code&gt; method, the package wraps the standard Pandas ‘apply’ method with a tqdm progress bar. This can come in really handy when you’re processing large data frames!&lt;/p&gt;</content><author><name>Mark Douthwaite</name></author><category term="data science" /><category term="python" /><summary type="html">Data Scientists can sometimes make life difficult for themselves simply because the focus of their work is relatively narrow in comparison to the capabilities of a language like Python. This series of posts looks at general-purpose packages that may save Data Scientists a fair bit of time.</summary></entry><entry><title type="html">Reading List 2018</title><link href="http://localhost:4000/ReadingList2018/" rel="alternate" type="text/html" title="Reading List 2018" /><published>2018-12-01T00:00:00+00:00</published><updated>2018-12-01T00:00:00+00:00</updated><id>http://localhost:4000/ReadingList2018</id><content type="html" xml:base="http://localhost:4000/ReadingList2018/">&lt;h2 id=&quot;a-quickish-word-about-books&quot;&gt;A Quick(ish) Word About Books&lt;/h2&gt;

&lt;p&gt;I think there is something profoundly healthy and ‘enlightening’ about reading long-form content, both fiction and non-fiction, that is not present in short-form content like many blogs (the irony, I know!), news articles and, to some extent, academic papers. I worry – maybe wrongly – that our current standard mechanisms for acquiring and ingesting information act to provide us with a huge number of paths to a relatively small number of narrow and somewhat anaemic sources of information.&lt;/p&gt;

&lt;p&gt;This has been driven home in recent years through direct exposure to the noise-making machinery that drives a not-insubstantial proportion of the internet. The sheer number of websites and social media accounts dedicated to re-branding, re-posting and generally amplifying content that is typically poorly researched and often sensationalised into bite-size 800-word-or-less chunks is quite disheartening. It sometimes seems like the entire apparatus is targeting the reader’s subconscious world rather than their conscious one.&lt;/p&gt;

&lt;p&gt;That’s where books can be great. At the outset, the reader enters into a relationship with the author. By committing to reading their book, we essentially agree to spend an extended period of time in the author’s company as they set out their narrative or discuss their ideas. We can get a sense for who the author is, and often a more holistic perspective on both who they are, their motives and &lt;em&gt;how&lt;/em&gt; they’re trying to get us (the reader) to think. We also get more time and content to process and reason about, giving us a richer, more in-depth grasp of the subject or themes we’re being shown. Sometimes – maybe most of the time – you simply cannot beat a good book. They are &lt;em&gt;investments&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;This brings me to this post. A few years ago I noticed I’d got out of the habit of reading long-form content regularly. I recall in that particular year I read only two or three books. The following year I set myself a target to read at least one book a month, and gradually this has crept up to something like 1.5 books a month presently. That’s still not as many as I’d like, but I’m in it for the long haul – hopefully I’ll get there!&lt;/p&gt;

&lt;p&gt;I wanted to highlight another point here too: I love working in software and specifically in my own little bit of AI. But that doesn’t mean I should spend every spare minute reading the latest papers and little else. We need to strive to be rounded, ethical and conscious of broader issues. That means looking outside our little silos, trying to understand other perspectives and actively searching for challenging work, and/or actively reading seminal work that we take for granted as knowing or not needing to read. That also means that non-scientific work can be very important too, including fictional works.&lt;/p&gt;

&lt;p&gt;I realise this perspective isn’t limited to just people working in AI, and I don’t think this is controversial or original, but I raise it as I have encountered many professionals in the commercial and research sectors that – in my opinion – focus too narrowly on minutiae that ultimately inadvertently limits their capabilities. That’s why I thought I’d put my reading list for the last year, and some books I’m expecting to read over the next year down. Hopefully there’s some books of interest in there too!&lt;/p&gt;

&lt;h2 id=&quot;top-5-books-of-2018&quot;&gt;Top 5 Books of 2018&lt;/h2&gt;

&lt;p&gt;Here are my top five favourite books from 2018 in no particular order:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Pale Fire&lt;/strong&gt;
  &lt;small&gt;&lt;em&gt;V. Nabokov, 1962&lt;/em&gt;&lt;/small&gt;
  &lt;br /&gt;A novel split between a 999 line poem accompanied by a long literary commentary, this book probably doesn’t sound like a particularly gripping read. However, these two primary elements combine to produce one of the most unconventional and compelling novels I’ve ever read. If you’re a fan of meta-fiction, you should definitely give this a go. This is a literary equivalent to the films that demand to be re-watched to discover new details and cross-references.
  &lt;br /&gt;&lt;a href=&quot;https://www.waterstones.com/book/pale-fire/vladimir-nabokov/mary-mccarthy/9780141185262&quot;&gt;Waterstones (UK)&lt;/a&gt;, &lt;a href=&quot;https://www.amazon.co.uk/Pale-Fire-Penguin-Modern-Classics/dp/0141185260&quot;&gt;Amazon&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Fall of the House of Usher and Other Writings&lt;/strong&gt; 
  &lt;small&gt;&lt;em&gt;E. A. Poe, 1839&lt;/em&gt;&lt;/small&gt;
  &lt;br /&gt;Prior to reading this collection of Poe’s writings, I’d never been directly exposed to Poe’s work. I’d come across links elsewhere (in Lovecraft’s work, for example), and these links had intrigued me, but I never quite got around to actually reading any of his work. This collection of stories is good, though the quality and clarity of some pieces does vary here and there. The titular short-story was a standout. The imagery and atmosphere created by Poe was for me almost crystalline, and I still have lingering images of some of the events over six months later. This is true of a couple of the other stories in this collection too (The Pendulum and The Masque of the Red Death being particular favourites).
  &lt;br /&gt;&lt;a href=&quot;https://www.waterstones.com/book/the-fall-of-the-house-of-usher-and-other-writings/edgar-allan-poe/harland-miller/9780141439815&quot;&gt;Waterstones (UK)&lt;/a&gt;, &lt;a href=&quot;https://www.amazon.co.uk/House-Usher-Writings-Penguin-Classics/dp/0141439815&quot;&gt;Amazon&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Iliad&lt;/strong&gt;
  &lt;small&gt;&lt;em&gt;Homer, circa 800BCE&lt;/em&gt;&lt;/small&gt;
  &lt;br /&gt;&lt;em&gt;The Iliad&lt;/em&gt; is one of those books that you essentially know the core themes and narrative without realising it, simply because so many later works draw &lt;em&gt;very&lt;/em&gt; heavily from it. For it’s historical significance alone it is worth a read – but it’s a great bit of storytelling too. There’s also an interesting link to Guy Deutscher’s &lt;em&gt;Through the Language Glass&lt;/em&gt;. That book is also worth a look if you’re interested in language and cognition.
  &lt;br /&gt;&lt;a href=&quot;https://www.waterstones.com/book/the-iliad/homer/martin-hammond/9780140444445&quot;&gt;Waterstones (UK)&lt;/a&gt;, &lt;a href=&quot;https://www.amazon.co.uk/Penguin-Classics-Homer-Iliad/dp/0140444440&quot;&gt;Amazon&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bhagavad Gita&lt;/strong&gt; 
  &lt;small&gt;&lt;em&gt;Anonymous, 300BCE-100CE&lt;/em&gt;&lt;/small&gt;
  &lt;br /&gt;This book is actually a 700 verse Sanskrit scripture that is a subset of one of the great Hindu epics: The &lt;em&gt;Mahabharata&lt;/em&gt;. It describes the discussions of the ancient Hindu prince Arjuna and Krishna, his charioteer (who is also an avatar of Lord Vishnu). The narrative revolves around a number of philosophical points related ostensibly to the rationale for Arjuna to go to war, but also links closely to more generic insights into other human struggles too. The climax of the narrative introduces some fascinating imagery around Time and Divinity that will stay with me for a while.
  &lt;br /&gt;&lt;a href=&quot;https://www.waterstones.com/book/the-bhagavad-gita/simon-brodbeck/laurie-l-patton/9780140447903&quot;&gt;Waterstones (UK)&lt;/a&gt;, &lt;a href=&quot;https://www.amazon.co.uk/Bhagavad-Gita-Penguin-Classics/dp/0140449183&quot;&gt;Amazon&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Neuromancer&lt;/strong&gt; 
  &lt;small&gt;&lt;em&gt;W. Gibson, 1984&lt;/em&gt;&lt;/small&gt;
  &lt;br /&gt;I was torn on whether to include this book in my top 5. In many ways Ursula Le Guin’s  &lt;em&gt;The Left Hand of Darkness&lt;/em&gt; is a more polished book that explores some still quite unconventional ideas in a very interesting way, and it may be better deserving of the spot. However, I am a &lt;em&gt;big&lt;/em&gt; fan of cyberpunk, and somehow this book simply resonated with me more at the time. Plus, alongside Blade Runner, this book kickstarted the cyberpunk aesthetic, so it’s a must read for me for that reason alone.
  &lt;br /&gt;&lt;a href=&quot;https://www.waterstones.com/book/neuromancer/william-gibson/9781473217386&quot;&gt;Waterstones (UK)&lt;/a&gt;, &lt;a href=&quot;https://www.amazon.co.uk/Neuromancer-S-F-MASTERWORKS-William-Gibson/dp/1473217385&quot;&gt;Amazon&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;honourable-mentions-for-2018&quot;&gt;Honourable Mentions for 2018&lt;/h2&gt;

&lt;p&gt;So I had a hard time picking a top 5, on a different day any one of these may have made it too:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Through the Language Glass&lt;/strong&gt; - &lt;em&gt;G. Deutscher&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Myth of Sisyphus&lt;/strong&gt; - &lt;em&gt;A. Camus&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Thing on the Doorstep&lt;/strong&gt; - &lt;em&gt;H. P. Lovecraft&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Left Hand of Darkness&lt;/strong&gt; - &lt;em&gt;U. Le Guin&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Prose Edda&lt;/strong&gt; - &lt;em&gt;S. Sturluson&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;East of Eden&lt;/strong&gt; - &lt;em&gt;J. Steinbeck&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;It Can’t Happen Here&lt;/strong&gt; - &lt;em&gt;S. Lewis&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Art of Meditation&lt;/strong&gt; - &lt;em&gt;M. Ricard&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Commandant of Auschwitz&lt;/strong&gt; - &lt;em&gt;R. Hoess&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;A Gentleman in Moscow&lt;/strong&gt; - &lt;em&gt;A. Towles&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Saga of Gunnlaug Serpent-Tongue&lt;/strong&gt; - &lt;em&gt;Anonymous&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Clean Code&lt;/strong&gt; - &lt;em&gt;R. Martin&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reading-list-so-far-for-2019&quot;&gt;Reading List (So Far!) for 2019&lt;/h2&gt;

&lt;p&gt;And finally, here’s some of the books I’m &lt;em&gt;currently&lt;/em&gt; planning on reading in 2019:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Gödel, Escher, Bach&lt;/strong&gt; - &lt;em&gt;D. Hofstadter&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Metamorphosis and Other Stories&lt;/strong&gt; - &lt;em&gt;F. Kafka&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Concepts of Modern Mathematics&lt;/strong&gt; - &lt;em&gt;I. Stewart&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Complete Poems&lt;/strong&gt; - &lt;em&gt;S. T. Coleridge&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Aeneid&lt;/strong&gt; - &lt;em&gt;Virgil&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Star Maker&lt;/strong&gt; - &lt;em&gt;O. Stapleton&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Outsider&lt;/strong&gt; - &lt;em&gt;A. Camus&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Odyssey&lt;/strong&gt; - &lt;em&gt;Homer&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Republic&lt;/strong&gt; - &lt;em&gt;Plato&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;History of Western Philosophy&lt;/strong&gt; - &lt;em&gt;B. Russell&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;An Enquiry Concerning Human Understanding&lt;/strong&gt; - &lt;em&gt;D. Hume&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;We Were The Future&lt;/strong&gt; - &lt;em&gt;Y. Newman&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The Undiscovered Self&lt;/strong&gt; - &lt;em&gt;C. G. Jung&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Six Not So Easy Pieces&lt;/strong&gt; - &lt;em&gt;R. Feynman&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Life 3.0&lt;/strong&gt; - &lt;em&gt;M. Tegmark&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Paradise Lost&lt;/strong&gt; - &lt;em&gt;J. Milton&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Mark Douthwaite</name></author><category term="books" /><category term="education" /><summary type="html">I've decided to jump on the bandwagon and give a list of my favourite books of 2019. There's also some thoughts on the importance of books more generally too.</summary></entry></feed>